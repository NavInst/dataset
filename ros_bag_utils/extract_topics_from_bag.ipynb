{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rosbag\n",
    "import csv\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "########## Modify the Configuration  Here ##########\n",
    "####################################################\n",
    "\n",
    "# Replace with your .bag file path\n",
    "bag_file = r\"./imus.bag\"  \n",
    "\n",
    "# Replace with the topics you want to extract\n",
    "topics = [\n",
    "    '/xsens/imu',  \n",
    "    '/obd2/speed'\n",
    "]\n",
    "\n",
    "# Replace with your output folder path.\n",
    "# The script will create csv file for every topic\n",
    "out_folder = r\"./\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_msg_fields(msg, prefix=''):\n",
    "    fields = {}\n",
    "    for field_name in msg.__slots__:\n",
    "        field_value = getattr(msg, field_name)\n",
    "        \n",
    "        # Check if the field is a ROS message by checking for __slots__ attribute\n",
    "        if hasattr(field_value, '__slots__'):\n",
    "            # Recurse into nested ROS messages\n",
    "            fields.update(extract_msg_fields(field_value, prefix + field_name + '.'))\n",
    "        else:\n",
    "            # Otherwise, add the field directly (primitive type or list of primitives)\n",
    "            fields[prefix + field_name] = field_value\n",
    "\n",
    "    return fields\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(bag_file, topics,out_folder):\n",
    "    if not os.path.isfile(bag_file):\n",
    "        print(f\"Error: Bag file '{bag_file}' does not exist.\")\n",
    "        return\n",
    "\n",
    "    \n",
    "    print(\"opening :\",bag_file)\n",
    "    bag = rosbag.Bag(bag_file, 'r')\n",
    "\n",
    "    # Check if the topics exist in the bag file\n",
    "    available_topics = bag.get_type_and_topic_info()[1].keys()\n",
    "    missing_topics = [topic for topic in topics if topic not in available_topics]\n",
    "    if missing_topics:\n",
    "        print(f\"Error: The following topics are not available in the bag file: {', '.join(missing_topics)}\")\n",
    "        bag.close()\n",
    "        return\n",
    "\n",
    "    #bag timing info\n",
    "    start_time = bag.get_start_time()\n",
    "    end_time = bag.get_end_time()\n",
    "    total_duration = end_time - start_time\n",
    "\n",
    "    # Open CSV writers for each topic\n",
    "    csv_writers = {}\n",
    "    for topic in topics:\n",
    "        csv_file = topic.replace('/', '_') + '.csv'\n",
    "        csv_file = csv_file.lstrip('_')\n",
    "        csv_file_path = os.path.join(out_folder,csv_file)\n",
    "        \n",
    "        csv_writers[topic] = {\n",
    "            \"path\":csv_file_path,\n",
    "            \"file\": open(csv_file_path, 'w', newline=''),\n",
    "            \"writer\": None  \n",
    "        }\n",
    "\n",
    "    last_time = start_time\n",
    "    for topic, msg, t in bag.read_messages(topics=topics):\n",
    "        # Calculate progress\n",
    "        current_time = t.to_sec()\n",
    "        elapsed_time = current_time - start_time\n",
    "        progress = (elapsed_time / total_duration) * 100\n",
    "\n",
    "        # Print progress Every second\n",
    "        if current_time - last_time >= 1: \n",
    "            sys.stdout.write(f\"\\rProcessing bag: {progress:.2f}% complete\")\n",
    "            sys.stdout.flush()\n",
    "            last_time = current_time\n",
    "\n",
    "\n",
    "        # Extract the message fields\n",
    "        msg_dict = {'time': t.to_sec()}\n",
    "        msg_dict.update(extract_msg_fields(msg))\n",
    "\n",
    "        # Initialize the CSV writer if not already done\n",
    "        if csv_writers[topic][\"writer\"] is None:\n",
    "            csv_writers[topic][\"writer\"] = csv.DictWriter(csv_writers[topic][\"file\"], fieldnames=msg_dict.keys())\n",
    "            csv_writers[topic][\"writer\"].writeheader()\n",
    "\n",
    "        # Write the message data\n",
    "        csv_writers[topic][\"writer\"].writerow(msg_dict)\n",
    "\n",
    "       \n",
    "    #Close the bag\n",
    "    bag.close()\n",
    "    sys.stdout.write(f\"\\rProcessing bag: 100.0% complete\")\n",
    "    sys.stdout.flush()\n",
    "    print()\n",
    "\n",
    "\n",
    "    # Close all CSV files\n",
    "    print(\"---------------------------------------------\")\n",
    "    for topic, writer_info in csv_writers.items():\n",
    "        writer_info[\"file\"].close()\n",
    "        print(f\"Data from topic '{topic}' saved to '{writer_info['path']}'\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_data(bag_file,topics,out_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
